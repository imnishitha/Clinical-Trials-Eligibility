{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5fe13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a3a6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {'input_ids': torch.tensor([   1,   15, 1075,  126,  194,  430,  105,  873]), 'attention_mask': torch.tensor([1, 1, 1, 1, 1, 1, 1, 1]), 'label': torch.tensor(1)}\n",
    "x = inputs['input_ids']\n",
    "embeddings = nn.Embedding(num_embeddings=16000, embedding_dim=128)\n",
    "sentence = embeddings(x).detach()\n",
    "sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a8d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1080, 0.2588, 0.1528,  ..., 0.5445, 0.1877, 0.8018],\n",
       "        [0.4910, 0.7235, 0.8743,  ..., 0.1006, 0.0645, 0.4158],\n",
       "        [0.0276, 0.1498, 0.7157,  ..., 0.3366, 0.6612, 0.2028],\n",
       "        ...,\n",
       "        [0.5456, 0.7573, 0.4561,  ..., 0.1805, 0.7653, 0.2535],\n",
       "        [0.9660, 0.0091, 0.2226,  ..., 0.5059, 0.7477, 0.2053],\n",
       "        [0.8256, 0.8324, 0.5988,  ..., 0.1746, 0.8806, 0.7699]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model, n_heads = 128, 8\n",
    "d_k = int(d_model/n_heads)\n",
    "d_q, d_v = d_k, d_k\n",
    "torch.nn.Parameter(torch.rand(d_model, d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b7946fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=128, out_features=16, bias=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q = torch.nn.Linear(in_features=d_model, out_features=d_k)\n",
    "W_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caec9dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q(sentence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "421cd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = W_q(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "546a9251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e23d26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5b94e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys.T == keys.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56fbed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884b20f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1927, -2.7106, -0.6197,  ...,  1.1473,  2.0553,  0.4151],\n",
       "         [ 0.1421, -0.7689,  0.3769,  ...,  0.0697,  1.1415,  0.1970],\n",
       "         [-1.8202, -1.3779,  1.0631,  ...,  0.1377,  0.0374,  1.6048],\n",
       "         ...,\n",
       "         [-0.7385, -0.2250, -1.9107,  ..., -0.1647,  1.0714, -0.9317],\n",
       "         [-0.0153,  0.5112, -0.6501,  ...,  0.7190, -0.0085, -0.5314],\n",
       "         [-0.4835,  0.1453, -0.5339,  ...,  0.5381,  0.3193,  0.6896]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[[-1.8459, -1.7282, -0.6483,  ...,  0.0543, -0.8648,  1.0076],\n",
       "          [-2.0549, -0.8155, -0.5276,  ..., -0.2688, -0.6486, -0.3124],\n",
       "          [ 0.1090,  0.5589,  1.1096,  ...,  0.3564,  1.5431, -0.2893],\n",
       "          ...,\n",
       "          [ 0.4605, -0.6430, -0.7065,  ...,  1.1937, -0.0493, -0.4530],\n",
       "          [ 1.8162,  0.5795, -0.2745,  ..., -1.2953, -1.0593,  0.3853],\n",
       "          [ 0.5429,  1.1721,  1.3245,  ...,  2.2241, -0.8260, -0.2536]]],\n",
       "        grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[[-2.0386, -4.4388, -1.2680,  ...,  1.2017,  1.1904,  1.4227],\n",
       "          [-1.9128, -1.5844, -0.1507,  ..., -0.1991,  0.4929, -0.1154],\n",
       "          [-1.7111, -0.8191,  2.1726,  ...,  0.4940,  1.5805,  1.3154],\n",
       "          ...,\n",
       "          [-0.2780, -0.8680, -2.6172,  ...,  1.0290,  1.0221, -1.3847],\n",
       "          [ 1.8008,  1.0908, -0.9246,  ..., -0.5763, -1.0678, -0.1460],\n",
       "          [ 0.0594,  1.3174,  0.7906,  ...,  2.7621, -0.5068,  0.4360]]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc = nn.Embedding(1024, 128)\n",
    "positions = torch.arange(0, len(x)).unsqueeze(dim=0)\n",
    "embeddings(x), pos_enc(positions), embeddings(x)+pos_enc(positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
